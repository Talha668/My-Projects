# -*- coding: utf-8 -*-
"""Collab Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17AvasHlnpTa7drY9pqlW_DVZrpdZ6y_G
"""

!pip install -q sentence-transformers faiss-cpu

import json
import pickle
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")

with open("dhafiles.json", "r", encoding="utf-8") as f:
  data = json.load(f)
print(f"Type of data: {type(data)}" )
print(f"Number of items in data: {len(data)}")

texts = []

# Access the list of properties from the "data" key
properties = data.get("data", [])

for item in properties:
    title = item.get("title", "")

    agent = item.get("agent", {})
    agent_name = agent.get("name", "")
    designation = agent.get("designation", "")
    phone = agent.get("phone", "")

    text = f"""
    Listing Title: {title}.
    Agent Name: {agent_name}.
    Agent Designation: {designation}.
    Contact Phone: {phone}.
    """

    texts.append(text.strip())

output = texts

embeddings = model.encode(
    texts,
    batch_size=64,
    show_progress_bar=True,
    convert_to_numpy=True
)

dimension = embeddings.shape[1]

nlist = int(np.sqrt(len(embeddings))) # Smart default
quantizer = faiss.IndexFlatL2(dimension)

index = faiss.IndexIVFFlat(
    quantizer,
    dimension,
    nlist,
    faiss.METRIC_L2
)

index.train(embeddings)
index.add(embeddings)

print("Total vectors indexed:", index.ntotal)

index.nprobe = 10  # 5-20 is good for 10k-100k

faiss.write_index(index, "dha_ivf.index")

with open("dha_texts.pkl", "wb") as f:
    pickle.dump(texts, f)

def search(query, k=1):
    q_emb = model.encode([query], convert_to_numpy=True)
    D, I = index.search(q_emb, k)
    return texts[I[0][0]], D[0][0]

print(search("Who is the agent for DHA Phase 6 commercial plot?"))