# -*- coding: utf-8 -*-
"""NLP Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qdycWK0onUXanz2PBbx3K3PpW90carF6

DHA APIs / JSON
    ↓
COLAB (Embedding + Indexing)
    ↓
faiss.index + records.pkl
    ↓
Django loads once at startup
    ↓
User query
    ↓
Phase/Sector extraction
    ↓
Listing OR Summary logic
    ↓
Answer
"""

!pip install -q sentence-transformers faiss-cpu

import re
import json
import pickle
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")

with open("dhafiles.json", "r", encoding="utf-8") as f:
    data = json.load(f)

print(type(data))
print(data)

def extract_phase(value):
  if not value:
    return None
  match = re.search(r"(\d+)", str(value))
  return match.group(1) if match else None

def normalize_price(price):
  if not price:
    return None

  price = str(price).lower()
  match = re.search(r"([\d\.]+)", price)
  if not match:
    return None

  value = float(match.group(1))

  if "crore" in price:
    return value * 10_000_000
  if "lakh" in price or "lac" in price:
    return value * 100_000

  return value

records = []

properties = data.get("data", [])

for item in properties:
  if not isinstance(item, dict):
    continue

  title = item.get("title", "")
  agent = item.get("agent", {})

  phase = extract_phase(item.get("phase"))

  subtype = f"{item.get('subtype', '')} {item.get('type', '')}".lower()
  sector = "commercial" if "commercial" in subtype else "residential"

  prop_type = item.get("type", "").lower()
  if "plot" in prop_type:
    prop_type_cat = "plot"
  elif "house" in prop_type:
    prop_type_cat = "house"
  else:
    prop_type_cat = "property"

  price = normalize_price(item.get("price"))

  record = {
      "text": (
          f"{title}. "
          f"Dha Phase: {phase}. "
          f"{sector.capitalize()} {prop_type_cat}. "
          f"Agent: {agent.get('name', '')}, "
          f"{agent.get('designation', '')}. "
          f"Contact: {agent.get('phone', '')}."
      ),
      "phase": phase,
      "sector": sector,
      "price": price,
      "type": prop_type_cat
  }

  records.append(record)

def normalize_price(text):
    if not text:
        return None
    text = text.lower()
    if "lakh" in text:
        return float(text.split()[0]) * 100000
    if "crore" in text:
        return float(text.split()[0]) * 10000000
    return None

print(len(records))
print(records[0])
print(
    min([r["price"] for r in records if r["price"]]),
    max([r["price"] for r in records if r["price"]])
)

texts = [r["text"] for r in records]

embeddings = model.encode(
    texts,
    batch_size=64,
    show_progress_bar=True,
    convert_to_numpy=True
)

dimension = embeddings.shape[1]
nlist = int(np.sqrt(len(embeddings)))

quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(
    quantizer,
    dimension,
    nlist,
    faiss.METRIC_L2
)

index.train(embeddings)
index.add(embeddings)
index.nprobe = 10

faiss.write_index(index, "dha_ivf.index")

with open("dha_records.pkl", "wb") as f:
    pickle.dump(records, f)